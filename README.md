Project Description:

A project that uses hand tracking technology to create an interactive application that allows the user to draw on a virtual whiteboard using the movement of his hand in front of the camera. The camera is displayed in a window next to the board, with the hand movement identified and highlighted using artificial intelligence and image processing techniques. The project relies on a framework to monitor the basic features of the hand and convert them into dynamic graphics on the screen.

Technologies used:

TensorFlow or Mediapipe library for hand tracking.

Python to develop the basic application.

Libraries for drawing such as OpenCV or Pygame.

A user interface to split the screen into two windows: the camera and the whiteboard.
Objectives:

Provide an innovative drawing experience without physical tools.

Enhance image processing applications in human-computer interaction.

The possibility of expanding the idea for educational or entertainment applications.


![image](https://github.com/user-attachments/assets/19e88d4f-27ff-4e62-9e6e-84c612568c02)
